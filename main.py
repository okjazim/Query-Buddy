"""
main.py - RAG Pipeline Orchestrator
====================================
Runs the complete pipeline: ingest â†’ chunk â†’ embed â†’ index

"""

import os
import sys
import time
from pathlib import Path

# Import pipeline modules
import ingest_sources
import chunk_text
import embed_store
import vector_store


class PipelineConfig:
    """Configuration for the RAG pipeline."""
    
    # Directory paths
    RAW_DIR = "data/raw"
    EMBEDDINGS_DIR = "data/embeddings"
    CHROMA_DIR = "./chroma_db"
    
    # File paths
    CHUNKS_PATH = "data/chunks.json"
    EMBEDDINGS_PATH = "data/embeddings/embeddings.npy"
    METADATA_PATH = "data/embeddings/metadata.json"
    
    @classmethod
    def print_paths(cls):
        """Print all configured paths."""
        print("\n" + "="*60)
        print("PIPELINE CONFIGURATION")
        print("="*60)
        print(f"Raw data:        {cls.RAW_DIR}")
        print(f"Chunks:          {cls.CHUNKS_PATH}")
        print(f"Embeddings:      {cls.EMBEDDINGS_PATH}")
        print(f"Metadata:        {cls.METADATA_PATH}")
        print(f"Vector Index:    {cls.CHROMA_DIR}")
        print("="*60 + "\n")


class PipelineRunner:
    """Orchestrates the RAG pipeline execution."""
    
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.timings = {}
    
    def log(self, message):
        """Print message if verbose mode is enabled."""
        if self.verbose:
            print(message)
    
    def run_step(self, step_name, step_function, *args, **kwargs):
        """
        Execute a pipeline step with timing and error handling.
        
        Args:
            step_name: Name of the step (for logging)
            step_function: Function to execute
            *args, **kwargs: Arguments to pass to the function
            
        Returns:
            Result of the function (if any)
        """
        self.log(f"\n{'='*60}")
        self.log(f"STEP: {step_name}")
        self.log(f"{'='*60}")
        
        start_time = time.time()
        
        try:
            result = step_function(*args, **kwargs)
            elapsed = time.time() - start_time
            self.timings[step_name] = elapsed
            
            self.log(f"âœ“ {step_name} completed in {elapsed:.2f}s")
            return result
            
        except Exception as e:
            self.log(f"âœ— {step_name} FAILED: {str(e)}")
            raise
    
    def run_full_pipeline(self, skip_ingest=False):
        """
        Run the complete RAG pipeline.
        
        Args:
            skip_ingest: If True, skip the ingestion step (useful if sources already ingested)
        """
        self.log("\n" + "ğŸš€ " * 20)
        self.log("STARTING RAG PIPELINE")
        self.log("ğŸš€ " * 20)
        
        PipelineConfig.print_paths()
        
        # Step 1: Ingest sources (PDFs + Web pages)
        if not skip_ingest:
            self.run_step(
                "1. Ingest Sources",
                ingest_sources.main
            )
        else:
            self.log("\nâ­ï¸  Skipping ingestion step (already done)")
        
        # Step 2: Chunk text
        self.run_step(
            "2. Chunk Text",
            chunk_text.process_all_files
        )
        
        # Step 3: Generate embeddings
        self.run_step(
            "3. Generate Embeddings",
            self._run_embed_store
        )
        
        # Step 4: Build vector index
        self.run_step(
            "4. Build Vector Index",
            self._run_vector_store
        )
        
        # Print summary
        self._print_summary()
    
    def _run_embed_store(self):
        """Execute the embedding generation step."""
        chunks = embed_store.load_chunks()
        model = embed_store.load_model()
        embeddings = embed_store.create_embeddings(chunks, model)
        embed_store.save_embeddings_and_metadata(embeddings, chunks)
    
    def _run_vector_store(self):
        """Execute the vector indexing step."""
        texts, embeddings, ids, metadata = vector_store.load_data()
        vector_store.store_in_chroma(texts, embeddings, ids, metadata)
    
    def _print_summary(self):
        """Print pipeline execution summary."""
        total_time = sum(self.timings.values())
        
        self.log("\n" + "="*60)
        self.log("PIPELINE SUMMARY")
        self.log("="*60)
        
        for step, elapsed in self.timings.items():
            percentage = (elapsed / total_time * 100) if total_time > 0 else 0
            self.log(f"{step:.<50} {elapsed:>6.2f}s ({percentage:>5.1f}%)")
        
        self.log(f"{'TOTAL TIME':.<50} {total_time:>6.2f}s")
        self.log("="*60)
        
        self.log("\nâœ… Pipeline completed successfully!")
        self.log(f"ğŸ“Š Vector database ready at: {PipelineConfig.CHROMA_DIR}")
        self.log("ğŸ” You can now run queries using rag_core.py or app.py")


def verify_dependencies():
    """Check if all required files and directories exist."""
    print("Checking pipeline dependencies...")
    
    issues = []
    
    # Check if raw sources exist
    if not os.path.exists(PipelineConfig.RAW_DIR):
        issues.append(f"âŒ Raw data directory not found: {PipelineConfig.RAW_DIR}")
    
    # Check if required scripts exist
    required_files = [
        "ingest_sources.py",
        "chunk_text.py",
        "embed_store.py",
        "vector_store.py"
    ]
    
    for file in required_files:
        if not os.path.exists(file):
            issues.append(f"âŒ Required file not found: {file}")
    
    if issues:
        print("\nâš ï¸  Issues found:")
        for issue in issues:
            print(f"  {issue}")
        return False
    
    print("âœ… All dependencies found\n")
    return True


def main():
    """Main entry point for the pipeline."""
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          RAG PIPELINE - QUERY BUDDY PROJECT             â•‘
    â•‘                                                          â•‘
    â•‘  Ingest â†’ Chunk â†’ Embed â†’ Index                         â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Verify dependencies
    if not verify_dependencies():
        print("\nâŒ Please fix the issues above before running the pipeline.")
        sys.exit(1)
    
    # Parse command line arguments
    skip_ingest = "--skip-ingest" in sys.argv
    quiet = "--quiet" in sys.argv
    
    if skip_ingest:
        print("â„¹ï¸  Running with --skip-ingest flag (will skip data ingestion)\n")
    
    # Run pipeline
    try:
        runner = PipelineRunner(verbose=not quiet)
        runner.run_full_pipeline(skip_ingest=skip_ingest)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Pipeline interrupted by user")
        sys.exit(1)
        
    except Exception as e:
        print(f"\n\nâŒ Pipeline failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()